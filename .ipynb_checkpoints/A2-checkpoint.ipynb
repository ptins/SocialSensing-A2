{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacc_dist(tweet1, tweet2):\n",
    "    a = set(tweet1.split(' '))\n",
    "    b = set(tweet2.split(' '))\n",
    "    a_and_b = a.intersection(b)\n",
    "    a_union_b = a.union(b)\n",
    "    return 1-len(a_and_b)/len(a_union_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_tweets(tweet_dict, centroid_ids):\n",
    "\n",
    "    # initialize centroid_dict\n",
    "    centroid_dict = {}\n",
    "    for centroid_id in centroid_ids:\n",
    "        centroid_dict[centroid_id] = []\n",
    "    \n",
    "    # get centroid texts for comparison/distance measure\n",
    "    centroid_text_list = [tweet_dict[tweet_id] for tweet_id in list(centroid_dict.keys())]\n",
    "\n",
    "    # loop through every tweet in tweet_dict\n",
    "    for tweet_id, tweet_text in tweet_dict.items():\n",
    "    \n",
    "        # get distances to each centroid\n",
    "        dist_to_centroid = [jacc_dist(tweet_text, centroid_text) for centroid_text in centroid_text_list]\n",
    "\n",
    "        # get index of closest centroid\n",
    "        index = np.argmin(dist_to_centroid)\n",
    "\n",
    "        # append tweet_id to closest centroid_id \n",
    "        centroid_dict[centroid_ids[index]].append(tweet_id)\n",
    "    \n",
    "    # return centroid_dict\n",
    "    return(centroid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_centers(tweet_dict, centroid_dict):\n",
    "    \n",
    "    # to store updated/new means\n",
    "    new_centroid_ids = []\n",
    "\n",
    "    # find updated mean for each centroid\n",
    "    for centroid_id, tweet_ids in centroid_dict.items():\n",
    "\n",
    "        centroid_min_dist = 1\n",
    "        centroid_min_dist_id = ''\n",
    "\n",
    "        # compute distance from 'this' tweet to 'other' tweets\n",
    "        for tweet_id in tweet_ids:\n",
    "\n",
    "            this_tweet   = tweet_dict[tweet_id]\n",
    "            other_tweets = [tweet_dict[other_id] for other_id in tweet_ids]\n",
    "\n",
    "            # calculate dist to other tweets\n",
    "            dist_to_other_tweets     = [jacc_dist(this_tweet, other_tweet) for other_tweet in other_tweets]\n",
    "            ave_dist_to_other_tweets = np.mean(dist_to_other_tweets)\n",
    "\n",
    "            # if 'this' tweet closer to other tweets, make it new center\n",
    "            if ave_dist_to_other_tweets < centroid_min_dist:\n",
    "                centroid_min_dist = ave_dist_to_other_tweets\n",
    "                centroid_min_dist_id = tweet_id\n",
    "\n",
    "        # append new centroid id to new list\n",
    "        new_centroid_ids.append(centroid_min_dist_id)\n",
    "\n",
    "    # return new means\n",
    "    return(new_centroid_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dict = {}\n",
    "for tweet in open('./tweets.json'):\n",
    "    tweet_json = json.loads(tweet)\n",
    "    tweet_dict[tweet_json['id']] = tweet_json['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./seeds.txt') as f:\n",
    "    centroid_ids = f.readlines()\n",
    "centroid_ids = [int(x.strip().replace(',','')) for x in centroid_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration #1: converging...\n",
      "iteration #2: converged\n"
     ]
    }
   ],
   "source": [
    "# tracking\n",
    "iter_no = 1\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    # cluster phase\n",
    "    cd = cluster_tweets(tweet_dict, centroid_ids)\n",
    "    \n",
    "    # save old centroids for checking convergence\n",
    "    centroid_ids_old = centroid_ids\n",
    "    \n",
    "    # update phase - new centroid_ids\n",
    "    centroid_ids = update_centers(tweet_dict, cd)\n",
    "\n",
    "    if centroid_ids == centroid_ids_old: # convergence reached\n",
    "        \n",
    "        print('iteration #{}: converged'.format(iter_no))\n",
    "        \n",
    "        # write to file\n",
    "        with open('results.txt', 'w') as file:\n",
    "             file.write(json.dumps(cd))\n",
    "        \n",
    "        # break out of loop\n",
    "        break\n",
    "        \n",
    "    else: # has not converged\n",
    "    \n",
    "        print('iteration #{}: converging...'.format(iter_no))\n",
    "        iter_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
